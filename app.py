import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Lasso
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# --- CSSë¥¼ ì´ìš©í•œ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë³€ê²½ ---
st.markdown("""
<style>
div.stButton > button:first-child {
    background-color: #000080; /* ë‚¨ìƒ‰ */
    color: white; /* ê¸€ììƒ‰ */
    border: none; /* í…Œë‘ë¦¬ ì—†ìŒ */
}
div.stButton > button:hover {
    background-color: #0000CD; /* ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ ìƒ‰ìƒ */
    color: white;
    border: none;
}
</style>""", unsafe_allow_html=True)


# Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • (í•„ìš” ì‹œ, ë§ëŠ” í°íŠ¸ ì´ë¦„ìœ¼ë¡œ ë³€ê²½)
# from matplotlib import font_manager, rc
# font_path = "c:/Windows/Fonts/malgun.ttf"
# font = font_manager.FontProperties(fname=font_path).get_name()
# rc('font', family=font)

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# --- Streamlit í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(layout="wide", page_title="APU Oil Temp ì˜ˆì¸¡ ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ")
st.title('APU Oil Temp ì˜ˆì¸¡ ì¸í„°ë™í‹°ë¸Œ ëŒ€ì‹œë³´ë“œ')

# --- ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ í•¨ìˆ˜ (ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ) ---
@st.cache_data
def load_data():
    """ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        df_data = pd.read_csv('APU_2023-06-29_2025-07-30_processedver2.csv')
        too_high = pd.read_csv('APU_high_temp_maint.csv')
        maint = pd.read_csv('APU_maint.csv')

        df_data.dropna(how='all', axis=1, inplace=True)
        df_data['CREATION_DATE'] = pd.to_datetime(df_data['CREATION_DATE'])

        too_high['NR_REQUEST_DATE'] = pd.to_datetime(too_high['NR_REQUEST_DATE'], errors='coerce')
        maint['NR_REQUEST_DATE'] = pd.to_datetime(maint['NR_REQUEST_DATE'], errors='coerce')
        
        return df_data, too_high, maint
    except FileNotFoundError as e:
        st.error(f"ì˜¤ë¥˜: '{e.filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ë“¤ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None

        
# --- ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ (ì¬ì‚¬ìš©ì„ ìœ„í•´ í•¨ìˆ˜ë¡œ ì •ì˜) ---
def preprocess_df(df_input):
    df_output = df_input.copy()

    if 'Date' in df_output.columns and not pd.api.types.is_datetime64_any_dtype(df_output['Date']):
        df_output['Date'] = pd.to_datetime(df_output['Date'])
    elif 'Date' not in df_output.columns:
        raise KeyError("Error: 'Date' column not found in the dataframe. Please ensure your data has a 'Date' column.")

    if 'REGNO' in df_output.columns:
        df_output.rename(columns={'REGNO': 'HL_no'}, inplace=True)
    elif 'HL_no' not in df_output.columns:
        raise KeyError("Error: Neither 'REGNO' nor 'HL_no' column found for aircraft identification. One of them is required.")

    if 'HL_no' in df_output.columns and 'Date' in df_output.columns:
        df_output = df_output.sort_values(by=['HL_no', 'Date'])
    else:
        print("Warning: Cannot sort by 'HL_no' or 'Date' as one or both columns are missing.")

# 'ì •ìƒ' ë°ì´í„° ë§ˆìŠ¤í¬ í•¨ìˆ˜
def get_normal_data_mask(df, fault_df, maint_df, tail_num, window_days=7):
    fault_dates = pd.to_datetime(fault_df[fault_df['AC_NO'] == tail_num]['NR_REQUEST_DATE'], errors='coerce').dropna()
    maint_dates = pd.to_datetime(maint_df[maint_df['AC_NO'] == tail_num]['NR_REQUEST_DATE'], errors='coerce').dropna()
    all_event_dates = pd.to_datetime(pd.concat([fault_dates, maint_dates]).unique(), errors='coerce').dropna()
    
    is_normal_data = pd.Series(True, index=df.index)
    for event_date in all_event_dates:
        start_exclusion = event_date - pd.Timedelta(days=window_days)
        end_exclusion = event_date
        is_normal_data &= ~((df['CREATION_DATE'] >= start_exclusion) & (df['CREATION_DATE'] <= end_exclusion))
    return is_normal_data

# --- ë°ì´í„° ë¡œë“œ ---
df_data, too_high, maint = load_data()

# ë°ì´í„° ë¡œë”© ì„±ê³µ ì‹œì—ë§Œ ì „ì²´ ì•± ì‹¤í–‰
if df_data is not None:
    # --- ì‚¬ì´ë“œë°” UI êµ¬ì„± ---
    st.sidebar.header('âš™ï¸ ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„ íƒ')

    # ë²„íŠ¼, ë©€í‹°ì…€ë ‰íŠ¸, ë“œë¡­ë‹¤ìš´ ë©”ë‰´ ë“± ì‚¬ì´ë“œë°” UI ìš”ì†Œë¥¼ ë‚¨ìƒ‰ í…Œë§ˆë¡œ ë³€ê²½
    st.markdown("""
    <style>
    /* ë¶„ì„ ì‹œì‘ ë²„íŠ¼ */
    div.stButton > button:first-child {
        background-color: #000080; /* ë‚¨ìƒ‰ */
        color: white;
        border: none;
    }
    div.stButton > button:hover {
        background-color: #4682B4; /* ë§ˆìš°ìŠ¤ ì˜¬ë ¸ì„ ë•Œ ë°ì€ ë‚¨ìƒ‰ */
        color: white;
        border: none;
    }

    /* í”¼ì²˜ ì„ íƒ(ë©€í‹°ì…€ë ‰íŠ¸)ì˜ ì„ íƒëœ í•­ëª© */
    span[data-baseweb="tag"] {
        background-color: #000080 !important;
    }

    /* ë“œë¡­ë‹¤ìš´ ë©”ë‰´ì— ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë ¸ì„ ë•Œ */
    li[data-baseweb="menu-item-wrapper"]:hover {
        background-color: #4682B4;
    }
    </style>""", unsafe_allow_html=True)

    all_features = ['N3EGTA', 'N3GLA', 'N3WB', 'N3PT', 'N3P2A', 'N3LCOT', 'N3LCIT', 'N3IGV', 'N3SCV', 'N3HOT', 'N3LOT']
    all_targets =  ['N3EGTA', 'N3GLA', 'N3WB', 'N3PT', 'N3P2A', 'N3LCOT', 'N3LCIT', 'N3IGV', 'N3SCV', 'N3HOT', 'N3LOT']
    available_tails = sorted(df_data['REGNO'].unique().astype(str))

    selected_tail = st.sidebar.selectbox('1. í•­ê³µê¸° ê¸°ë²ˆ ì„ íƒ:', available_tails, index=available_tails.index('HL8001'))
    selected_target = st.sidebar.selectbox('2. ì˜ˆì¸¡ íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ:', all_targets)
    
    # íƒ€ê²Ÿìœ¼ë¡œ ì„ íƒëœ ë³€ìˆ˜ëŠ” í”¼ì²˜ ëª©ë¡ì—ì„œ ìë™ ì œì™¸
    available_features = [f for f in all_features if f != selected_target]
    selected_features = st.sidebar.multiselect('3. í•™ìŠµ í”¼ì²˜ ë³€ìˆ˜ ì„ íƒ:', available_features, default=available_features)

    # --- ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ---
    if st.sidebar.button('ğŸ“Š ë¶„ì„ ì‹œì‘', type="primary"):
        with st.spinner('ëª¨ë¸ í•™ìŠµ ë° ì‹œê°í™” ì§„í–‰ ì¤‘...'):
            
            # --- ì›ë³¸ ì½”ë“œì˜ í•µì‹¬ ë¡œì§ ì‹œì‘ ---
            
            # 1. ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°’ìœ¼ë¡œ ë³€ìˆ˜ ì„¤ì •
            tail = selected_tail
            features = selected_features
            target = selected_target

            # 2. ë°ì´í„° ë¶„ë¦¬
            train_end_date = pd.to_datetime('2024-12-31')
            df_train = df_data[df_data['CREATION_DATE'] <= train_end_date].copy()
            df_test = df_data[df_data['CREATION_DATE'] > train_end_date].copy()

            df_train_tail = df_train[df_train['REGNO'] == tail].copy().sort_values(by='CREATION_DATE')
            df_test_tail = df_test[df_test['REGNO'] == tail].copy().sort_values(by='CREATION_DATE')

            if len(df_train_tail) < 30:
                st.warning(f"í•­ê³µê¸° {tail}ì˜ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            else:
                st.success(f"í•­ê³µê¸°: {tail} ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                
                # 3. ëª¨ë¸ í•™ìŠµ
                normal_mask = get_normal_data_mask(df_train_tail, too_high, maint, tail, window_days=7)
                X_train_full = df_train_tail[features]
                y_train_full = df_train_tail[target]
                X_train_normal = X_train_full[normal_mask]
                y_train_normal = y_train_full[normal_mask]
                
                if len(X_train_normal) < 30:
                    st.warning("ì •ë¹„/ê³ ì¥ ì´ë ¥ ì œì™¸ í›„ í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                else:
                    preprocessor = ColumnTransformer([('scaler', StandardScaler(), features)], remainder='drop')
                    pipeline = Pipeline([('preprocessor', preprocessor), ('regressor', Lasso(max_iter=10000))])
                    tscv = TimeSeriesSplit(n_splits=5)
                    param_grid = {'regressor__alpha': [0.001, 0.01, 0.1, 1, 10]}
                    search = GridSearchCV(pipeline, param_grid=param_grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)
                    search.fit(X_train_normal, y_train_normal)
                    best_model = search.best_estimator_

                    st.write(f"**ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!** (ìµœì  Alpha: `{search.best_params_['regressor__alpha']}`)")

                    # 4. ì˜ˆì¸¡ ë° ì”ì°¨ ê³„ì‚°
                    df_train_tail['Predicted'] = best_model.predict(X_train_full)
                    df_train_tail['Residual'] = df_train_tail[target] - df_train_tail['Predicted']

                    # 5. í•™ìŠµ ê¸°ê°„ ì‹œê°í™” ë° ì •ë¹„ ê¸°ë¡ ì¶œë ¥
                    st.markdown("---")
                    st.subheader('1. í•™ìŠµ ê¸°ê°„(Training Period) ë¶„ì„')

                    # í•™ìŠµ ê¸°ê°„ ì •ë¹„ ê¸°ë¡ ì²˜ë¦¬
                    maint_records_train_period = maint[(maint['AC_NO'] == tail) & (maint['NR_REQUEST_DATE'] >= df_train_tail['CREATION_DATE'].min()) & (maint['NR_REQUEST_DATE'] <= df_train_tail['CREATION_DATE'].max())].copy()
                    fault_dates_train = too_high[(too_high['AC_NO'] == tail) & (too_high['NR_REQUEST_DATE'] >= df_train_tail['CREATION_DATE'].min()) & (too_high['NR_REQUEST_DATE'] <= df_train_tail['CREATION_DATE'].max())]['NR_REQUEST_DATE'].dropna()

                    # ì‹œê°í™” 1: í•™ìŠµ ê¸°ê°„
                    fig1, axes1 = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
                    sns.lineplot(x='CREATION_DATE', y=target, data=df_train_tail, label=f'Actual {target}', color='blue', ax=axes1[0], marker='o', markersize=3)
                    sns.lineplot(x='CREATION_DATE', y='Predicted', data=df_train_tail, label=f'Predicted {target}', color='red', linestyle='--', ax=axes1[0])
                    for i, date in enumerate(fault_dates_train):
                        axes1[0].axvline(x=date, color='black', linestyle='-', linewidth=1.5, label='High Temp Fault' if i == 0 else "")
                    
                    # (ì½”ë“œ ì¤‘ëµ) ì›ë³¸ê³¼ ë™ì¼í•œ ì •ë¹„ ê¸°ë¡ ì‹œê°í™” ë¡œì§
                    plotted_maint_labels_train = {'Maint. Record': False, 'Special Maint.': False}
                    for date in maint_records_train_period['NR_REQUEST_DATE'].dropna().unique():
                        daily_maint_data = maint_records_train_period[maint_records_train_period['NR_REQUEST_DATE'] == date]
                        malfunction_text = " ".join(daily_maint_data['MALFUNCTION'].dropna().astype(str).str.upper())
                        action_text = " ".join(daily_maint_data['CORRECTIVE_ACTION'].dropna().astype(str).str.upper())
                        line_color, line_label = ('orange', 'Maint. Record')
                        if 'ODOR' in malfunction_text or 'CLEAN' in action_text:
                            line_color, line_label = ('green', 'Special Maint.')
                        if not plotted_maint_labels_train[line_label]:
                            axes1[0].axvline(x=date, color=line_color, linestyle='-', linewidth=1.5, label=line_label)
                            plotted_maint_labels_train[line_label] = True
                        else:
                            axes1[0].axvline(x=date, color=line_color, linestyle='-', linewidth=1.5)
                    
                    axes1[0].set_title(f'{target}: Actual vs. Prediction (Aircraft: {tail}, Training Period)'); axes1[0].set_ylabel(f'{target} Value'); axes1[0].grid(True)
                    handles, labels = axes1[0].get_legend_handles_labels()
                    axes1[0].legend(dict(zip(labels, handles)).values(), dict(zip(labels, handles)).keys())
                    axes1[1].fill_between(df_train_tail['CREATION_DATE'], df_train_tail['Residual'], 0, where=(df_train_tail['Residual'] > 0), color='red', alpha=0.3, label='Positive Residual (Model Under-predicts)')
                    axes1[1].fill_between(df_train_tail['CREATION_DATE'], df_train_tail['Residual'], 0, where=(df_train_tail['Residual'] < 0), color='blue', alpha=0.3, label='Negative Residual (Model Over-predicts)')
                    axes1[1].axhline(y=0, color='gray', linestyle='--'); axes1[1].set_title(f'Residuals of {target} Prediction'); axes1[1].set_xlabel('Date'); axes1[1].set_ylabel('Residual Value'); axes1[1].legend(); axes1[1].grid(True)
                    plt.tight_layout()
                    st.pyplot(fig1)

                    # í•™ìŠµ ê¸°ê°„ ì •ë¹„ ê¸°ë¡ í…Œì´ë¸” ì¶œë ¥
                    st.write("#### í•™ìŠµ ê¸°ê°„ ì •ë¹„ ê¸°ë¡")
                    if not maint_records_train_period.empty:
                        maint_records_train_period['DATE_STR'] = maint_records_train_period['NR_REQUEST_DATE'].dt.strftime('%Y-%m-%d')
                        grouped_maint = maint_records_train_period.groupby('DATE_STR').agg({'MALFUNCTION': lambda x: '; '.join(x.dropna().astype(str).unique()), 'CORRECTIVE_ACTION': lambda x: '; '.join(x.dropna().astype(str).unique())}).reset_index()
                        st.dataframe(grouped_maint)
                    else:
                        st.info("í•´ë‹¹ ê¸°ê°„ì— ì •ë¹„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

                    # 6. ì˜ˆì¸¡ ê¸°ê°„ ë¶„ì„
                    if not df_test_tail.empty:
                        st.markdown("---")
                        st.subheader('2. ì˜ˆì¸¡ ê¸°ê°„(Test Period) ë¶„ì„')
                        
                        df_test_tail['Predicted'] = best_model.predict(df_test_tail[features])
                        df_test_tail['Residual'] = df_test_tail[target] - df_test_tail['Predicted']

                        maint_records_test_period = maint[(maint['AC_NO'] == tail) & (maint['NR_REQUEST_DATE'] >= df_test_tail['CREATION_DATE'].min()) & (maint['NR_REQUEST_DATE'] <= df_test_tail['CREATION_DATE'].max())].copy()
                        fault_dates_test = too_high[(too_high['AC_NO'] == tail) & (too_high['NR_REQUEST_DATE'] >= df_test_tail['CREATION_DATE'].min()) & (too_high['NR_REQUEST_DATE'] <= df_test_tail['CREATION_DATE'].max())]['NR_REQUEST_DATE'].dropna()

                        # ì‹œê°í™” 2: ì˜ˆì¸¡ ê¸°ê°„
                        fig2, axes2 = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
                        sns.lineplot(x='CREATION_DATE', y=target, data=df_test_tail, label=f'Actual {target}', color='blue', ax=axes2[0], marker='o', markersize=3)
                        sns.lineplot(x='CREATION_DATE', y='Predicted', data=df_test_tail, label=f'Predicted {target}', color='red', linestyle='--', ax=axes2[0])
                        # (ì½”ë“œ ì¤‘ëµ) ì›ë³¸ê³¼ ë™ì¼í•œ ì •ë¹„ ê¸°ë¡ ì‹œê°í™” ë¡œì§ ..
                        for i, date in enumerate(fault_dates_test):
                            axes2[0].axvline(x=date, color='black', linestyle='-', linewidth=1.5, label='High Temp Fault' if i == 0 else "")
                        
                        plotted_maint_labels_test = {'Maint. Record': False, 'Special Maint.': False}
                        for date in maint_records_test_period['NR_REQUEST_DATE'].dropna().unique():
                            daily_maint_data = maint_records_test_period[maint_records_test_period['NR_REQUEST_DATE'] == date]
                            malfunction_text = " ".join(daily_maint_data['MALFUNCTION'].dropna().astype(str).str.upper())
                            action_text = " ".join(daily_maint_data['CORRECTIVE_ACTION'].dropna().astype(str).str.upper())
                            line_color, line_label = ('orange', 'Maint. Record')
                            if 'ODOR' in malfunction_text or 'CLEAN' in action_text:
                                line_color, line_label = ('green', 'Special Maint.')
                            if not plotted_maint_labels_test[line_label]:
                                axes2[0].axvline(x=date, color=line_color, linestyle='-', linewidth=1.5, label=line_label)
                                plotted_maint_labels_test[line_label] = True
                            else:
                                axes2[0].axvline(x=date, color=line_color, linestyle='-', linewidth=1.5)

                        axes2[0].set_title(f'{target}: Actual vs. Prediction (Aircraft: {tail}, Prediction Period)'); axes2[0].set_ylabel(f'{target} Value'); axes2[0].grid(True)
                        handles, labels = axes2[0].get_legend_handles_labels()
                        axes2[0].legend(dict(zip(labels, handles)).values(), dict(zip(labels, handles)).keys())
                        axes2[1].fill_between(df_test_tail['CREATION_DATE'], df_test_tail['Residual'], 0, where=(df_test_tail['Residual'] > 0), color='red', alpha=0.3, label='Positive Residual')
                        axes2[1].fill_between(df_test_tail['CREATION_DATE'], df_test_tail['Residual'], 0, where=(df_test_tail['Residual'] < 0), color='blue', alpha=0.3, label='Negative Residual')
                        axes2[1].axhline(y=0, color='gray', linestyle='--'); axes2[1].set_title(f'Residuals of {target} Prediction'); axes2[1].set_xlabel('Date'); axes2[1].set_ylabel('Residual Value'); axes2[1].legend(); axes2[1].grid(True)
                        plt.tight_layout()
                        st.pyplot(fig2)

                        # ì˜ˆì¸¡ ê¸°ê°„ ì •ë¹„ ê¸°ë¡ í…Œì´ë¸” ì¶œë ¥
                        st.write("#### ì˜ˆì¸¡ ê¸°ê°„ ì •ë¹„ ê¸°ë¡")
                        if not maint_records_test_period.empty:
                            maint_records_test_period['DATE_STR'] = maint_records_test_period['NR_REQUEST_DATE'].dt.strftime('%Y-%m-%d')
                            grouped_maint_test = maint_records_test_period.groupby('DATE_STR').agg({'MALFUNCTION': lambda x: '; '.join(x.dropna().astype(str).unique()), 'CORRECTIVE_ACTION': lambda x: '; '.join(x.dropna().astype(str).unique())}).reset_index()
                            st.dataframe(grouped_maint_test)
                        else:
                            st.info("í•´ë‹¹ ê¸°ê°„ì— ì •ë¹„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("í•´ë‹¹ í•­ê³µê¸°ëŠ” ì˜ˆì¸¡ ê¸°ê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

