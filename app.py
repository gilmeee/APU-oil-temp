import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.ensemble import IsolationForest
import plotly.express as px
import plotly.graph_objects as go
import base64
import os
import matplotlib.font_manager as fm

# --- ê¸°ë³¸ ì„¤ì • ---
warnings.filterwarnings('ignore')
st.set_page_config(layout="wide", page_title="APU ê²°í•¨ ì˜ˆì¸¡ ë° ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# --- í°íŠ¸ íŒŒì¼ ì¸ì½”ë”© í•¨ìˆ˜ (CSS ì „ìš©) ---
def encode_font(font_path: str):
    if not os.path.exists(font_path):
        # CSSìš© í°íŠ¸ê°€ ì—†ì–´ë„ ì•±ì€ ëŒì•„ê°€ê²Œ í•˜ê³ , ê²½ê³ ë§Œ í‘œì‹œ
        st.warning(f"CSSìš© í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {font_path}")
        return None
    with open(font_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • (ê·¸ë˜í”„ ì „ìš©) ---
def set_matplotlib_korean_font():
    # 1) ë¡œì»¬ì— ë‘” Hanjin í°íŠ¸ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
    for p in ["HanjinGroupSans.ttf", "HanjinGroupSansBold.ttf"]:
        if os.path.exists(p):
            try:
                fm.fontManager.addfont(p)
                name = fm.FontProperties(fname=p).get_name()
                plt.rcParams["font.family"] = name
                break
            except Exception:
                pass
    else:
        # 2) ì—†ìœ¼ë©´ matplotlib ë‚´ì¥ í°íŠ¸ë¡œ ì•ˆì „í•˜ê²Œ
        plt.rcParams["font.family"] = "DejaVu Sans"

    # ìŒìˆ˜ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€
    plt.rcParams["axes.unicode_minus"] = False
    return plt.rcParams["font.family"]


# (ì„ íƒ) ë””ë²„ê·¸: ì‹¤ì œ ì ìš©ëœ í°íŠ¸ëª… í™•ì¸í•˜ê³  ì‹¶ìœ¼ë©´ ë‹¤ìŒ ì¤„ ì£¼ì„ í•´ì œ
# st.caption(f"matplotlib font â†’ {set_matplotlib_korean_font()}")
set_matplotlib_korean_font()
# --- í°íŠ¸ ì¸ì½”ë”© ì‹¤í–‰ ---
# ì¼ë°˜ ê¸€ì”¨ì²´ì™€ êµµì€ ê¸€ì”¨ì²´ë¥¼ ê°ê° ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
regular_font_encoded = encode_font("HanjinGroupSans.ttf")
bold_font_encoded = encode_font("HanjinGroupSansBold.ttf")

# --- CSS ìŠ¤íƒ€ì¼ ---
# í°íŠ¸ ì¸ì½”ë”©ì´ ì„±ê³µí–ˆì„ ê²½ìš°ì—ë§Œ CSSë¥¼ ì ìš©í•©ë‹ˆë‹¤.
if regular_font_encoded and bold_font_encoded:
    st.markdown(f"""
    <style>
        /* 1. í°íŠ¸ ì •ì˜: ì¼ë°˜ì²´ì™€ êµµì€ì²´ë¥¼ ëª¨ë‘ ë“±ë¡í•©ë‹ˆë‹¤ */
        @font-face {{
            font-family: 'Hanjin Group Sans';
            src: url(data:font/ttf;base64,{regular_font_encoded}) format('truetype');
            font-weight: normal;
        }}

        @font-face {{
            font-family: 'Hanjin Group Sans';
            src: url(data:font/ttf;base64,{bold_font_encoded}) format('truetype');
            font-weight: bold;
        }}

        /* 2. í°íŠ¸ ì ìš©: ì œëª©(h1) ë“±ì„ í¬í•¨í•œ ëª¨ë“  ìš”ì†Œì— ê°•ì œë¡œ ì ìš©í•©ë‹ˆë‹¤ */
        html, body, [class*="st-"], h1, h2, h3, h4, h5, h6 {{
            font-family: 'Hanjin Group Sans', sans-serif !important;
        }}

        /* Material Icon classì—ëŠ” ì €í¬ í°íŠ¸ê°€ ì ìš©ë˜ì§€ ì•Šë„ë¡ ì˜ˆì™¸ ì²˜ë¦¬ */
        .material-icons, .MuiIcon-root, .st-icon {{
            font-family: 'Material Icons' !important;
            font-style: normal;
            font-weight: normal;
            font-size: 24px;
            line-height: 1;
            letter-spacing: normal;
            text-transform: none;
            display: inline-block;
            white-space: nowrap;
            direction: ltr;
            -webkit-font-feature-settings: 'liga';
            -webkit-font-smoothing: antialiased;
        }}

        /* --- ì´í•˜ ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€ --- */
        .stDataFrame th, .stDataFrame td {{
            text-align: center !important;
        }}
        .stDataFrame thead tr th:first-child, .stDataFrame tbody tr th {{
            text-align: left !important;
        }}
        div.stButton > button:first-child {{
            background-color: #000080; color: white; border: none;
            border-radius: 8px; padding: 16px 32px; font-size: 18px;
            font-weight: bold; width: 100%;
        }}
        div.stButton > button:hover {{
            background-color: #4682B4; color: white; border: none;
        }}
        span[data-baseweb="tag"], [data-testid="stTag"] {{
            background-color: #000080 !important;
            color: white !important;
        }}
        div[data-testid="stSelectbox"] div[data-baseweb="select"],
        div[data-testid="stMultiSelect"] div[data-baseweb="select"] {{
            background-color: white; border: 1px solid #000080;
            border-radius: 5px; box-shadow: none;
        }}
        div[data-testid="stSelectbox"] div[data-baseweb="select"]:focus-within,
        div[data-testid="stMultiSelect"] div[data-baseweb="select"]:focus-within {{
            border-color: #000080;
            box-shadow: 0 0 0 2px #4682B4 !important;
            outline: none;
        }}
        .legend-container {{
            display: flex; gap: 20px; margin-top: -10px; margin-bottom: 10px;
        }}
        .legend-item {{
            display: flex; align-items: center; font-size: 14px;
        }}
        .color-box {{
            width: 20px; height: 20px; margin-right: 8px; border: 1px solid #ccc;
        }}
    </style>
    """, unsafe_allow_html=True)

# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ---
# ê·¸ë˜í”„ì˜ í•œê¸€ì€ ì•ˆì •ì ì¸ 'ë§‘ì€ ê³ ë”•'ì„ ì‚¬ìš©í•˜ë„ë¡ ì§ì ‘ ì§€ì •í•©ë‹ˆë‹¤.
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False
# ----------------------------------

# --- íƒ€ì´í‹€ ---
st.title('APU ê²°í•¨ ì˜ˆì¸¡ ë° ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ')
st.caption('ëª¨ë“  í•­ê³µê¸° ë°ì´í„°ë¥¼ í•™ìŠµí•œ ë‹¨ì¼ í†µí•© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í•­ê³µê¸°ì˜ ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.') #made with í•œì§„ í°íŠ¸

# --- ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ (ìºì‹±ìœ¼ë¡œ ì†ë„ ê·¹ëŒ€í™”) ---
@st.cache_data
def preprocess_data():
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df_data = pd.read_csv('APU_2023-06-29_2025-07-30_processedver2.csv')
        maint = pd.read_csv('APU_maint.csv')
        
        # ì»¬ëŸ¼ ì´ë¦„ì—ì„œ 'N3' ì œê±°
        df_data.rename(columns={
            'CREATION_DATE': 'DATE',
            'REGNO': 'AC_NO',
            'N3EGTA': 'EGTA',
            'N3GLA': 'GLA',
            'N3WB': 'WB',
            'N3PT': 'PT',
            'N3P2A': 'P2A',
            'N3LCOT': 'LCOT',
            'N3LCIT': 'LCIT',
            'N3IGV': 'IGV',
            'N3SCV': 'SCV',
            'N3HOT': 'HOT',
            'N3LOT': 'LOT'
        }, inplace=True)

        # 2. ê¸°ë³¸ ì „ì²˜ë¦¬ (ë‚ ì§œ ë³€í™˜ ë° ì´ë¦„ í†µì¼)
        df_data['DATE'] = pd.to_datetime(df_data['DATE'])
        maint['NR_REQUEST_DATE'] = pd.to_datetime(maint['NR_REQUEST_DATE'], errors='coerce')
        
        # 3. ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ìƒì„±
        df_data = df_data.sort_values(by=['AC_NO', 'DATE'])
        df_data['hour'] = df_data['DATE'].dt.hour
        df_data['month'] = df_data['DATE'].dt.month
        df_data['dayofweek'] = df_data['DATE'].dt.dayofweek
        df_data['month_sin'] = np.sin(2 * np.pi * df_data['month'] / 12)
        df_data['month_cos'] = np.cos(2 * np.pi * df_data['month'] / 12)

        # 4. MALFUNCTION íŠ¹ì„± ìƒì„±
        maint_for_merge = maint[['AC_NO', 'NR_REQUEST_DATE', 'MALFUNCTION']].copy()
        maint_for_merge.rename(columns={'NR_REQUEST_DATE': 'DATE'}, inplace=True)
        maint_for_merge.dropna(subset=['MALFUNCTION'], inplace=True)
        maint_for_merge['MALFUNCTION'] = maint_for_merge['MALFUNCTION'].astype(str)

        maint_ata_pivot = maint_for_merge.pivot_table(
            index=['AC_NO', 'DATE'],
            columns='MALFUNCTION', 
            aggfunc=lambda x: 1,
            fill_value=0
        ).reset_index()
        
        # ë©€í‹° ì¸ë±ìŠ¤ ì»¬ëŸ¼ ì´ë¦„ ì •ë¦¬
        new_cols = [f'ATA_{col}' for col in maint_ata_pivot.columns if col not in ['AC_NO', 'DATE']]
        maint_ata_pivot.columns = ['AC_NO', 'DATE'] + new_cols
        
        # 5. ì›ë³¸ ë°ì´í„°ì— ATA íŠ¹ì„± ë³‘í•©
        df_processed = pd.merge(df_data, maint_ata_pivot, on=['AC_NO', 'DATE'], how='left')
        ata_cols = [col for col in df_processed.columns if col.startswith('ATA_')]
        df_processed[ata_cols] = df_processed[ata_cols].fillna(0)

        return df_processed, maint, ata_cols

    except FileNotFoundError as e:
        st.error(f"ì˜¤ë¥˜: '{e.filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSV íŒŒì¼ë“¤ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None

# --- í†µí•© ëª¨ë¸ í•™ìŠµ (ìºì‹±ìœ¼ë¡œ ë™ì¼ ì¡°ê±´ ì¬í•™ìŠµ ë°©ì§€) ---
@st.cache_data
def train_unified_model(df, target, numerical_features, categorical_features):
    """
    ì „ì²´ ë°ì´í„°ë¥¼ ë°›ì•„ í†µí•© ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , ì‹œê³„ì—´ êµì°¨ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    target, featuresê°€ ë°”ë€” ë•Œë§Œ ì¬í•™ìŠµë©ë‹ˆë‹¤.
    """
    # 1. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì •ì˜
    train_start = pd.to_datetime("2023-06-01")
    train_end = pd.to_datetime("2024-05-31")
    df_train = df[(df['DATE'] >= train_start) & (df['DATE'] <= train_end)].copy()

    X_train = df_train[numerical_features + categorical_features]
    y_train = df_train[target]

    # 2. ëª¨ë¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
    preprocessor = ColumnTransformer(
        [
            ('scaler_numerical', StandardScaler(), numerical_features),
            ('onehot_categorical', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ],
        remainder='drop'
    )
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', Lasso(alpha=0.01, max_iter=10000))
    ])

    # 3. ì‹œê³„ì—´ êµì°¨ ê²€ì¦ (TimeSeriesSplit)
    tscv = TimeSeriesSplit(n_splits=5)
    cv_scores = {'MAE': [], 'RMSE': [], 'R2': []}

    for train_index, test_index in tscv.split(X_train):
        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]
        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]
        
        pipeline.fit(X_train_fold, y_train_fold)
        preds = pipeline.predict(X_test_fold)
        
        cv_scores['MAE'].append(mean_absolute_error(y_test_fold, preds))
        cv_scores['RMSE'].append(np.sqrt(mean_squared_error(y_test_fold, preds)))
        cv_scores['R2'].append(r2_score(y_test_fold, preds))

    # 4. ìµœì¢… ëª¨ë¸ í•™ìŠµ (ì „ì²´ í•™ìŠµ ë°ì´í„° ì‚¬ìš©)
    pipeline.fit(X_train, y_train)

    return pipeline, cv_scores

# --- ë°ì´í„° ë¡œë“œ ---
df_processed, maint, ata_cols = preprocess_data()

# ë°ì´í„° ë¡œë”© ì„±ê³µ ì‹œì—ë§Œ ì „ì²´ ì•± ì‹¤í–‰
if df_processed is not None:
    # --- ì‚¬ì´ë“œë°” UI êµ¬ì„± ---
    st.sidebar.header('ë¶„ì„ ì˜µì…˜ ì„ íƒ')

    # 1. ë¶„ì„í•  í•­ê³µê¸° ì„ íƒ
    available_tails = sorted(df_processed['AC_NO'].unique().astype(str))
    selected_tail = st.sidebar.selectbox('1. ë¶„ì„í•  í•­ê³µê¸° ì„ íƒ:', available_tails, index=available_tails.index('HL8001'))
    
    # 2. ë¨¸ì‹ ëŸ¬ë‹ ë° Raw ë°ì´í„° ì‹œê°í™” ì²´í¬ë°•ìŠ¤
    run_ml_prediction = st.sidebar.checkbox('ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ì‹¤í–‰', value=False)
    visualize_raw_data = st.sidebar.checkbox('Raw ë°ì´í„° ì‹œê°í™”', value=False)

    # ë¨¸ì‹ ëŸ¬ë‹ ì„ íƒ ì‹œ ê´€ë ¨ ì˜µì…˜ í‘œì‹œ
    if run_ml_prediction:
        st.sidebar.markdown("---")
        st.sidebar.header('ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡ ì„¤ì •')
        base_features = ['EGTA', 'GLA', 'WB', 'PT', 'P2A', 'LCOT', 'LCIT', 'IGV', 'SCV', 'HOT', 'LOT']
        selected_target = st.sidebar.selectbox('ì˜ˆì¸¡ íƒ€ê²Ÿ ë³€ìˆ˜ ì„ íƒ:', base_features, index=len(base_features)-1)
        available_features_for_ui = [f for f in base_features if f != selected_target]
        selected_base_features = st.sidebar.multiselect('í•™ìŠµ í”¼ì²˜ ì„ íƒ:',
                                                        available_features_for_ui,
                                                        default=available_features_for_ui)

    # Raw ë°ì´í„° ì‹œê°í™” ì„ íƒ ì‹œ ê´€ë ¨ ì˜µì…˜ í‘œì‹œ
    if visualize_raw_data:
        st.sidebar.markdown("---")
        st.sidebar.header('Raw ë°ì´í„° ì‹œê°í™” ì„¤ì •')
        base_features = ['EGTA', 'GLA', 'WB', 'PT', 'P2A', 'LCOT', 'LCIT', 'IGV', 'SCV', 'HOT', 'LOT']
        selected_raw_features = st.sidebar.multiselect(
            'ì‹œê°í™”í•  í”¼ì²˜ ì„ íƒ:',
            base_features,
            default=['LOT','HOT']
        )

    # --- ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ---
    if st.sidebar.button('ë¶„ì„ ì‹œì‘', type="primary") or 'analysis_done' in st.session_state:
        st.session_state['analysis_done'] = True
        
        if not run_ml_prediction and not visualize_raw_data:
            st.info("ì‹¤í–‰í•  ë¶„ì„ ì˜µì…˜ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
        # --- 1. Raw ë°ì´í„° ì‹œê°í™” ëª¨ë“œ ---
        if visualize_raw_data:
            st.subheader(f"ğŸ“Š {selected_tail} - Raw ë°ì´í„° ì‹œê°í™”")
            
            df_raw_plot = df_processed[df_processed['AC_NO'] == selected_tail].copy()
            
            if df_raw_plot.empty:
                st.warning(f"ì„ íƒëœ í•­ê³µê¸°({selected_tail})ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            elif not selected_raw_features:
                st.warning("ì‹œê°í™”í•  í”¼ì²˜ë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                fig_raw = go.Figure()
                for feature in selected_raw_features:
                    fig_raw.add_trace(go.Scatter(
                        x=df_raw_plot['DATE'],
                        y=df_raw_plot[feature],
                        mode='lines',
                        name=feature,
                        line={'width': 2},
                        hovertemplate='ê°’: %{y:.2f}'
                    ))
                
                fig_raw.update_layout(
                    title=f'{selected_tail} - {", ".join(selected_raw_features)} ë°ì´í„° ì¶”ì´',
                    xaxis_title='ë‚ ì§œ',
                    yaxis_title='ê°’',
                    hovermode="x unified",
                    xaxis={'dtick': 'M3', 'tickformat': '%Y-%m-%d'}
                )
                st.plotly_chart(fig_raw, use_container_width=True)

                st.write(f"ğŸ“ˆ {selected_tail}ì˜ {', '.join(selected_raw_features)} ì „ì²´ ê¸°ê°„ ë°ì´í„°")
                
                display_cols = ['DATE'] + selected_raw_features
                st.dataframe(df_raw_plot[display_cols], height=240, use_container_width=True)
        
            st.markdown("---")

        # --- 2. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë“œ ---
        if run_ml_prediction:
            with st.spinner('í†µí•© ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼ ë¶„ì„ ì¤‘...'):
                
                feature_names_dict = {
                    'EGTA': 'APU ë°°ê¸° ê°€ìŠ¤ ì˜¨ë„', 'GLA': 'APU ë°œì „ê¸° ë¶€í•˜',
                    'WB': 'ë³´ì •ëœ ë¶€í•˜ ì••ì¶•ê¸° ê³µê¸° ê³µê¸‰ëŸ‰', 'PT': 'ë¸”ë¦¬ë“œ ê³µê¸° ì••ë ¥',
                    'P2A': 'APU í¡ì… ì••ë ¥', 'LCOT': 'ë¶€í•˜ ì••ì¶•ê¸° ì¶œêµ¬ ì˜¨ë„',
                    'LCIT': 'ë¶€í•˜ ì••ì¶•ê¸° ì…êµ¬ ì˜¨ë„', 'IGV': 'í¡ì… ê³µê¸° ì¡°ì ˆê¹ƒ ìœ„ì¹˜',
                    'SCV': 'ì••ë ¥ ì¡°ì ˆ ë°¸ë¸Œ ìœ„ì¹˜', 'HOT': 'High Oil Temperature',
                    'LOT': 'Low Oil Temperature',
                }

                time_features = ['hour', 'month_sin', 'month_cos', 'dayofweek']
                selected_features = selected_base_features + time_features
                numerical_features = [f for f in selected_features if f in feature_names_dict or f in time_features]
                categorical_features = ata_cols
                all_model_features = numerical_features + categorical_features

                trained_pipeline, cv_scores = train_unified_model(df_processed, selected_target, numerical_features, categorical_features)
                
                df_processed['Predicted'] = trained_pipeline.predict(df_processed[all_model_features])
                df_processed['Residual'] = df_processed[selected_target] - df_processed['Predicted']
                df_tail_analysis = df_processed[df_processed['AC_NO'] == selected_tail].copy()
                
                df_plot = df_tail_analysis

                # --- ì„ íƒí•œ í•­ê³µê¸° ì˜ˆì¸¡ ë° ë¶„ì„ (ì „ì²´ ê¸°ê°„) ---
                st.subheader(f"1. {selected_tail} - {selected_target} ì˜ˆì¸¡ ë¶„ì„")
                
                # === ìˆ˜ì •ëœ ë¶€ë¶„: í† ê¸€ ë²„íŠ¼ ë ˆì´ë¸” ë³€ê²½ ===
                show_details = st.toggle(
                    "ìë™ ì´ìƒì¹˜ íƒì§€ ë° ëª¨ë¸ ì„¸ë¶€ ì •ë³´ í‘œì‹œ", 
                    value=False, 
                    help="í™œì„±í™”í•˜ë©´ ê·¸ë˜í”„ì— ì˜ˆì¸¡ ì´ìƒì¹˜ë¥¼ í‘œì‹œí•˜ê³ , í•˜ë‹¨ì— ì´ìƒì¹˜ ëª©ë¡ê³¼ ëª¨ë¸ ìƒì„¸ ì •ë³´ë¥¼ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤."
                )
                
                if df_plot.empty:
                    st.warning(f"{selected_tail}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    model = IsolationForest(contamination=0.01, random_state=42)
                    model.fit(df_plot[[selected_target, 'Predicted']])
                    df_plot['outlier'] = model.fit_predict(df_plot[[selected_target, 'Predicted']])
                    outliers_df = df_plot[df_plot['outlier'] == -1].copy()
                    
                    unfiltered_outliers_exist = not outliers_df.empty 
                    plot_title_period = "ì „ì²´ ê¸°ê°„"
                    
                    # HL8001ì´ ì„ íƒëœ ê²½ìš°, ì‹œê°í™”í•  ê¸°ê°„ì„ 24ë…„ 7ì›”ë¶€í„° 25ë…„ 3ì›”ê¹Œì§€ë¡œ ì œí•œ
                    if selected_tail == 'HL8001':
                        start_date = pd.to_datetime('2024-07-01')
                        end_date = pd.to_datetime('2025-03-31')
                        # í”Œë¡¯ ë°ì´í„° í•„í„°ë§
                        df_plot = df_plot[(df_plot['DATE'] >= start_date) & (df_plot['DATE'] <= end_date)].copy()
                        # í”Œë¡¯ê³¼ ëª©ë¡ì— í‘œì‹œë  ì´ìƒì¹˜ ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ í•„í„°ë§
                        outliers_df = outliers_df[(outliers_df['DATE'] >= start_date) & (outliers_df['DATE'] <= end_date)].copy()
                        plot_title_period = "2024ë…„ 7ì›” ~ 2025ë…„ 3ì›”"

                    fig, axes = plt.subplots(2, 1, figsize=(15, 8), sharex=True)
                    
                    maint_dates = maint[maint['AC_NO'] == selected_tail]['NR_REQUEST_DATE'].dropna()
                    
                    sns.lineplot(x='DATE', y=selected_target, data=df_plot, label=f'ì‹¤ì œ {selected_target}', color='blue', ax=axes[0], marker='o', markersize=3, alpha=0.7, errorbar=None)
                    sns.lineplot(x='DATE', y='Predicted', data=df_plot, label=f'ì˜ˆì¸¡ {selected_target}', color='red', linestyle='--', ax=axes[0], errorbar=None)
                    
                    if show_details and not outliers_df.empty:
                        axes[0].scatter(x=outliers_df['DATE'], y=outliers_df[selected_target], color='red', s=100, marker='X', label='Isolation Forest ì´ìƒì¹˜', zorder=5)

                    for i, date in enumerate(maint_dates.unique()):
                        axes[0].axvline(x=date, color='gold', linestyle='-', linewidth=4, label='ì •ë¹„ ê¸°ë¡' if i == 0 else "")
                    axes[0].set_title(f'{selected_tail} - {selected_target} ì˜ˆì¸¡ê°’ ë¶„ì„ ({plot_title_period})', fontsize=16)
                    axes[0].set_ylabel(f'{selected_target} ê°’')
                    axes[0].grid(True, linestyle='--', alpha=0.6)
                    axes[0].legend()

                    max_abs_residual = df_plot['Residual'].abs().max() if not df_plot.empty else 20
                    y_limit = max(20, max_abs_residual + 5)
                    axes[1].fill_between(df_plot['DATE'], df_plot['Residual'], 0, where=(df_plot['Residual'] > 0), color='red', alpha=0.3, label='ê³¼ì†Œ ì˜ˆì¸¡ (ì‹¤ì œê°’ > ì˜ˆì¸¡ê°’)')
                    axes[1].fill_between(df_plot['DATE'], df_plot['Residual'], 0, where=(df_plot['Residual'] < 0), color='blue', alpha=0.3, label='ê³¼ëŒ€ ì˜ˆì¸¡ (ì‹¤ì œê°’ < ì˜ˆì¸¡ê°’)')
                    axes[1].axhline(y=0, color='gray', linestyle='--')
                    axes[1].set_ylim(-y_limit, y_limit)
                    
                    if show_details and not outliers_df.empty:
                        axes[1].scatter(x=outliers_df['DATE'], y=outliers_df['Residual'], color='red', s=100, marker='X', label='Isolation Forest ì´ìƒì¹˜', zorder=5)

                    for i, date in enumerate(maint_dates.unique()):
                        axes[1].axvline(x=date, color='gold', linestyle='-', linewidth=4, label='ì •ë¹„ ê¸°ë¡' if i == 0 else "")

                    axes[1].set_title('ì˜ˆì¸¡ ì”ì°¨ (Residuals)', fontsize=16)
                    axes[1].set_xlabel('ë‚ ì§œ')
                    axes[1].set_ylabel('ì”ì°¨ ê°’')
                    axes[1].grid(True, linestyle='--', alpha=0.6)
                    axes[1].legend()

                    plt.tight_layout()
                    st.pyplot(fig)

                # --- ì •ë¹„ ê¸°ë¡ (í•­ìƒ í‘œì‹œ) ---
                st.markdown("---")
                st.markdown(f"##### {selected_tail} ì •ë¹„ ê¸°ë¡ (ì „ì²´ ê¸°ê°„)")
                maint_records = maint[maint['AC_NO'] == selected_tail].copy()
                if not maint_records.empty:
                    maint_records['DATE_STR'] = maint_records['NR_REQUEST_DATE'].dt.strftime('%Y-%m-%d')
                    display_df = maint_records[['DATE_STR', 'MALFUNCTION', 'MALFUNCTION_ATA', 'CORRECTIVE_ACTION']].sort_values(by='DATE_STR', ascending=True)
                    display_df.index = np.arange(1, len(display_df) + 1)
                    st.dataframe(display_df)
                else:
                    st.info("í•´ë‹¹ ê¸°ê°„ì— ì •ë¹„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                
                if show_details:
                    # --- ì´ìƒì¹˜ ëª©ë¡ ì„¹ì…˜ ---
                    st.markdown("---")
                    st.subheader(f"2. ìë™ìœ¼ë¡œ ê°ì§€ëœ ì´ìƒì¹˜ ëª©ë¡ ({selected_tail})")
                    if not outliers_df.empty:
                        display_outliers = outliers_df[['DATE', selected_target, 'Predicted', 'Residual']].copy()
                        display_outliers['DATE_STR'] = display_outliers['DATE'].dt.strftime('%Y-%m-%d %H:%M:%S')
                        display_outliers.rename(columns={'DATE_STR': 'ë‚ ì§œ', selected_target: 'ì‹¤ì œê°’', 'Predicted': 'ì˜ˆì¸¡ê°’', 'Residual': 'ì”ì°¨'}, inplace=True)
                        display_outliers.index = np.arange(1, len(display_outliers) + 1)
                        st.dataframe(display_outliers[['ë‚ ì§œ', 'ì‹¤ì œê°’', 'ì˜ˆì¸¡ê°’', 'ì”ì°¨']], height=240)
                    else:
                        if unfiltered_outliers_exist and selected_tail == 'HL8001':
                            st.info(f"í‘œì‹œëœ ê¸°ê°„({plot_title_period}) ë‚´ì—ì„œëŠ” ìë™ìœ¼ë¡œ ê°ì§€ëœ ì´ìƒì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("Isolation Forest ë¶„ì„ ê²°ê³¼, ì´ìƒì¹˜ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    
                    # --- ëª¨ë¸ ê´€ë ¨ ì„¸ë¶€ì‚¬í•­ ì„¹ì…˜ ---
                    st.markdown("---")
                    st.subheader("3. ëª¨ë¸ ê´€ë ¨ ì„¸ë¶€ì‚¬í•­")
                    
                    model_col1, model_col2 = st.columns(2)
                    
                    with model_col1:
                        st.markdown("#### 3-1. í†µí•© ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦")
                        st.write("ì‹œê³„ì—´ êµì°¨ê²€ì¦(TimeSeriesSplit, n=5) í‰ê·  ì„±ëŠ¥:")
                        st.metric("RÂ² Score", f"{np.mean(cv_scores['R2']):.3f}")
                        st.markdown("RÂ² ì ìˆ˜ëŠ” **1ì— ê°€ê¹Œìš¸ìˆ˜ë¡** ëª¨ë¸ì´ ë°ì´í„°ë¥¼ ì˜ ì„¤ëª…í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.")
                    
                    with model_col2:
                        st.markdown("#### 3-2. í•™ìŠµì— ì‚¬ìš©ëœ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
                        
                        numerical_feature_names = numerical_features
                        onehot_encoder = trained_pipeline.named_steps['preprocessor'].named_transformers_['onehot_categorical']
                        categorical_feature_names = list(onehot_encoder.get_feature_names_out(categorical_features))
                        
                        def get_korean_name(feature):
                            if feature in feature_names_dict:
                                return f'{feature} ({feature_names_dict[feature]})'
                            elif feature.startswith('ATA_'):
                                return f'{feature} (ì •ë¹„ ì½”ë“œ)'
                            else:
                                return feature
                        
                        all_feature_names = [get_korean_name(f) for f in numerical_feature_names] + [get_korean_name(f) for f in categorical_feature_names]
                        
                        coefficients = trained_pipeline.named_steps['regressor'].coef_
                        
                        feature_importance_df = pd.DataFrame({
                            'Feature': all_feature_names,
                            'Coefficient': coefficients
                        })
                        
                        feature_importance_df = feature_importance_df[feature_importance_df['Coefficient'] != 0].copy()
                        feature_importance_df['Abs_Coefficient'] = feature_importance_df['Coefficient'].abs()
                        feature_importance_df = feature_importance_df.sort_values(by='Abs_Coefficient', ascending=False)
                        
                        if not feature_importance_df.empty:
                            fig_importance, ax = plt.subplots(figsize=(5, len(feature_importance_df) * 0.5))
                            heatmap_data = feature_importance_df[['Coefficient']].set_index(feature_importance_df['Feature'])
                            
                            sns.heatmap(
                                heatmap_data, 
                                annot=True, 
                                fmt=".2f", 
                                cmap='coolwarm', 
                                center=0,
                                cbar_kws={'label': 'íšŒê·€ ê³„ìˆ˜'},
                                ax=ax
                            )
                            ax.set_ylabel('')
                            ax.set_xlabel('íšŒê·€ ê³„ìˆ˜')
                            ax.set_title(f'í†µí•© ëª¨ë¸ í”¼ì²˜ ì¤‘ìš”ë„', fontsize=16)
                            plt.yticks(rotation=0)
                            plt.tight_layout()
                            st.pyplot(fig_importance)
                            
                            st.markdown(f"""
                            **íšŒê·€ ê³„ìˆ˜ í•´ì„:**
                            - **ì–‘ìˆ˜(+)** ê³„ìˆ˜: í”¼ì²˜ ê°’ì´ ì¦ê°€í• ìˆ˜ë¡ íƒ€ê²Ÿ ë³€ìˆ˜($$ {selected_target} $$) ê°’ë„ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. (ì •ë¹„ë¡€)
                            - **ìŒìˆ˜(-)** ê³„ìˆ˜: í”¼ì²˜ ê°’ì´ ì¦ê°€í• ìˆ˜ë¡ íƒ€ê²Ÿ ë³€ìˆ˜($$ {selected_target} $$) ê°’ì€ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. (ë°˜ë¹„ë¡€)
                            - **ì ˆëŒ“ê°’**ì´ í´ìˆ˜ë¡ ëª¨ë¸ì˜ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ í¬ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
                            """)
                        else:
                            st.info("Lasso ëª¨ë¸ì˜ í˜ë„í‹° ì„¤ì •ìœ¼ë¡œ ì¸í•´ ëª¨ë“  í”¼ì²˜ì˜ ê³„ìˆ˜ê°€ 0ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.")
